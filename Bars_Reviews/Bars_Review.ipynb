{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, codecs, json, sys, gc\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "from spacy.lang import en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_directory = r\"/home/oleksandr/Dropbox/Deep_Learning/YouTube/Modern_NLP\"\n",
    "data_directory = \"\" #\"E:\\\\Dropbox\\\\Deep_Learning\\\\YouTube\\\\Modern_NLP\"\n",
    "\n",
    "business_filepath   = os.path.join(data_directory,'dataset','business.json')\n",
    "reviews_filepath    = os.path.join(data_directory,'dataset','review.json')\n",
    "review_txt_filepath = os.path.join(data_directory,'review_text_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"business_id\": \"YDf95gJZaq05wvo7hTQbbQ\", \"name\": \"Richmond Town Square\", \"neighborhood\": \"\", \"address\": \"691 Richmond Rd\", \"city\": \"Richmond Heights\", \"state\": \"OH\", \"postal_code\": \"44143\", \"latitude\": 41.5417162, \"longitude\": -81.4931165, \"stars\": 2.0, \"review_count\": 17, \"is_open\": 1, \"attributes\": {\"RestaurantsPriceRange2\": 2, \"BusinessParking\": {\"garage\": false, \"street\": false, \"validated\": false, \"lot\": true, \"valet\": false}, \"BikeParking\": true, \"WheelchairAccessible\": true}, \"categories\": [\"Shopping\", \"Shopping Centers\"], \"hours\": {\"Monday\": \"10:00-21:00\", \"Tuesday\": \"10:00-21:00\", \"Friday\": \"10:00-21:00\", \"Wednesday\": \"10:00-21:00\", \"Thursday\": \"10:00-21:00\", \"Sunday\": \"11:00-18:00\", \"Saturday\": \"10:00-21:00\"}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of a business record\n",
    "with codecs.open(business_filepath,encoding='utf_8') as f:\n",
    "    test = f.readline()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"review_id\":\"VfBHSwC5Vz_pbFluy07i9Q\",\"user_id\":\"cjpdDjZyprfyDG3RlkVG3w\",\"business_id\":\"uYHaNptLzDLoV_JZ_MuzUA\",\"stars\":5,\"date\":\"2016-07-12\",\"text\":\"My girlfriend and I stayed here for 3 nights and loved it. The location of this hotel and very decent price makes this an amazing deal. When you walk out the front door Scott Monument and Princes street are right in front of you, Edinburgh Castle and the Royal Mile is a 2 minute walk via a close right around the corner, and there are so many hidden gems nearby including Calton Hill and the newly opened Arches that made this location incredible.\\n\\nThe hotel itself was also very nice with a reasonably priced bar, very considerate staff, and small but comfortable rooms with excellent bathrooms and showers. Only two minor complaints are no telephones in room for room service (not a huge deal for us) and no AC in the room, but they have huge windows which can be fully opened. The staff were incredible though, letting us borrow umbrellas for the rain, giving us maps and directions, and also when we had lost our only UK adapter for charging our phones gave us a very fancy one for free.\\n\\nI would highly recommend this hotel to friends, and when I return to Edinburgh (which I most definitely will) I will be staying here without any hesitation.\",\"useful\":0,\"funny\":0,\"cool\":0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of a review record\n",
    "with codecs.open(reviews_filepath,encoding='utf_8') as f:\n",
    "    test = f.readline()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Restaurants', 51613),\n",
       " ('Shopping', 24595),\n",
       " ('Food', 23014),\n",
       " ('Beauty & Spas', 15139),\n",
       " ('Home Services', 13202),\n",
       " ('Health & Medical', 12033),\n",
       " ('Nightlife', 11364),\n",
       " ('Bars', 9868),\n",
       " ('Automotive', 9476),\n",
       " ('Local Services', 9343),\n",
       " ('Event Planning & Services', 8038),\n",
       " ('Active Life', 7427),\n",
       " ('Fashion', 6299),\n",
       " ('Sandwiches', 5864),\n",
       " ('Fast Food', 5792),\n",
       " ('American (Traditional)', 5737),\n",
       " ('Pizza', 5652),\n",
       " ('Coffee & Tea', 5565),\n",
       " ('Hair Salons', 5395),\n",
       " ('Hotels & Travel', 5188)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting categories\n",
    "categories = list()\n",
    "with codecs.open(business_filepath,encoding='utf_8') as f:\n",
    "    for line in f:\n",
    "        business = json.loads(line)\n",
    "        categories.append(business[u'categories'])\n",
    "flat_list = [item for sublist in categories for item in sublist]\n",
    "categories = Counter(flat_list)\n",
    "#print('There are {0:d} categories'.format(len(flat_list)))\n",
    "\n",
    "# displaying most common categories\n",
    "categories.most_common(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9868 bars IDs\n"
     ]
    }
   ],
   "source": [
    "# Collecting Bars IDs\n",
    "bar_ids = set()\n",
    "with codecs.open(business_filepath,encoding='utf_8') as f:\n",
    "    for line in f:\n",
    "        business = json.loads(line)\n",
    "        if u'Bars' not in business[u'categories']:\n",
    "            continue\n",
    "        bar_ids.add(business[u'business_id'])\n",
    "        \n",
    "\n",
    "bar_ids = frozenset(bar_ids)\n",
    "\n",
    "print('There are {0:d} bars IDs'.format(len(bar_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 714912 reviews\n"
     ]
    }
   ],
   "source": [
    "# Fetching reviews and storing them into txt file\n",
    "review_count = 0\n",
    "with codecs.open(review_txt_filepath,'w',encoding='utf_8') as review_txt:\n",
    "    with codecs.open(reviews_filepath, encoding='utf_8') as reviews_json:\n",
    "        for review_json in reviews_json:\n",
    "            review = json.loads(review_json)\n",
    "            if review[u'business_id'] not in bar_ids:\n",
    "                continue\n",
    "            review_txt.write(review[u'text'].replace('\\n','')+'\\n')\n",
    "            review_count += 1\n",
    "\n",
    "print('There are {0:d} reviews'.format(review_count))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('en_core_web_md')\n",
    "nlp =  spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So I know Christy's is a Madison tradition with those lovely views of Lake Waubesa. But this place is a one-track pony... location, location, location. This is a family-owned bar/restaurant and the owners know they have a captive audience. The beer is cold and the food is average, but the service is atrocious. On a recent beautiful Saturday afternoon, there were only two servers for the outside seating area.  There's no host, so we (4 adults and 1 kid) sat at a picnic table and proceeded to wait at least 10 minutes to no avail. We eventually went inside to order drinks and lunch. At no time during our visit did a server ever approach our table. I'd certainly be inclined to write off this awful experience to a bad day or poor staffing, but unfortunately this is more the rule rather than exception. One really weird thing is the Friday Fish Fry that features a special menu available ONLY inside, this isn't communicated very well;  so you'll grab a table outside, wait to order only to learn you can only order from the pizza/sandwich menu.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample review\n",
    "with codecs.open(review_txt_filepath, encoding='utf_8') as f:\n",
    "    sample_review = list(it.islice(f,0,10))[1]\n",
    "    \n",
    "\n",
    "print(sample_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 162 ms, sys: 12.2 ms, total: 174 ms\n",
      "Wall time: 73.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parsed_review = nlp(sample_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : So I know Christy's is a Madison tradition with those lovely views of Lake Waubesa.\n",
      "\n",
      "2 : But this place is a one-track pony... location, location, location.\n",
      "\n",
      "3 : This is a family-owned bar/restaurant and the owners know they have a captive audience.\n",
      "\n",
      "4 : The beer is cold and the food is average, but the service is atrocious.\n",
      "\n",
      "5 : On a recent beautiful Saturday afternoon, there were only two servers for the outside seating area.  \n",
      "\n",
      "6 : There's no host, so we (4 adults and 1 kid) sat at a picnic table and proceeded to wait at least 10 minutes to no avail.\n",
      "\n",
      "7 : We eventually went inside to order drinks and lunch.\n",
      "\n",
      "8 : At no time during our visit did a server ever approach our table.\n",
      "\n",
      "9 : I'd certainly be inclined to write off this awful experience to a bad day or poor staffing, but unfortunately this is more the rule rather than exception.\n",
      "\n",
      "10 : One really weird thing is the Friday Fish Fry that features a special menu available ONLY inside, this isn't communicated very well;  so you'll grab a table outside, wait to order only to learn you can only order from the pizza/sandwich menu.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# segmentation\n",
    "sents = parsed_review.sents\n",
    "for num, sent in enumerate(sents):\n",
    "    print(num+1,\":\",sent)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Fremont, about four, Vegas, )"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_review.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Christy - PERSON\n",
      "2 : Madison - PERSON\n",
      "3 : Lake Waubesa - LOC\n",
      "4 : one - CARDINAL\n",
      "5 : Saturday - DATE\n",
      "6 : afternoon - TIME\n",
      "7 : only two - CARDINAL\n",
      "8 : 4 - CARDINAL\n",
      "9 : 1 - CARDINAL\n",
      "10 : at least 10 minutes - TIME\n",
      "11 : One - CARDINAL\n",
      "12 :   - NORP\n",
      "13 : \n",
      " - GPE\n"
     ]
    }
   ],
   "source": [
    "# Named entity detection\n",
    "for num, entity in enumerate(parsed_review.ents):\n",
    "    print(num+1,':',entity,'-',entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>part_of_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christy</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'s</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Madison</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tradition</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>those</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lovely</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>views</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lake</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Waubesa</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>But</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>place</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>one</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>track</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pony</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>...</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>location</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>location</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>very</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>well</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>;</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>so</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>you</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>'ll</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>grab</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>table</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>outside</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>wait</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>order</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>only</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>learn</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>you</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>can</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>only</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>order</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>pizza</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>sandwich</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>menu</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token part_of_speech\n",
       "0           So            ADV\n",
       "1            I           PRON\n",
       "2         know           VERB\n",
       "3      Christy          PROPN\n",
       "4           's           PART\n",
       "5           is           VERB\n",
       "6            a            DET\n",
       "7      Madison          PROPN\n",
       "8    tradition           NOUN\n",
       "9         with            ADP\n",
       "10       those            DET\n",
       "11      lovely            ADJ\n",
       "12       views           NOUN\n",
       "13          of            ADP\n",
       "14        Lake          PROPN\n",
       "15     Waubesa          PROPN\n",
       "16           .          PUNCT\n",
       "17         But          CCONJ\n",
       "18        this            DET\n",
       "19       place           NOUN\n",
       "20          is           VERB\n",
       "21           a            DET\n",
       "22         one            NUM\n",
       "23           -          PUNCT\n",
       "24       track           NOUN\n",
       "25        pony           NOUN\n",
       "26         ...          PUNCT\n",
       "27    location           NOUN\n",
       "28           ,          PUNCT\n",
       "29    location           NOUN\n",
       "..         ...            ...\n",
       "194       very            ADV\n",
       "195       well            ADV\n",
       "196          ;          PUNCT\n",
       "197                     SPACE\n",
       "198         so            ADP\n",
       "199        you           PRON\n",
       "200        'll           VERB\n",
       "201       grab           VERB\n",
       "202          a            DET\n",
       "203      table           NOUN\n",
       "204    outside            ADV\n",
       "205          ,          PUNCT\n",
       "206       wait           VERB\n",
       "207         to           PART\n",
       "208      order           VERB\n",
       "209       only            ADV\n",
       "210         to           PART\n",
       "211      learn           VERB\n",
       "212        you           PRON\n",
       "213        can           VERB\n",
       "214       only            ADV\n",
       "215      order           VERB\n",
       "216       from            ADP\n",
       "217        the            DET\n",
       "218      pizza           NOUN\n",
       "219          /            SYM\n",
       "220   sandwich           NOUN\n",
       "221       menu           NOUN\n",
       "222          .          PUNCT\n",
       "223         \\n          SPACE\n",
       "\n",
       "[224 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part of speech tagging\n",
    "tokens    = [token.orth_ for token in parsed_review]\n",
    "token_pos = [token.pos_ for token in parsed_review]\n",
    "\n",
    "pd.DataFrame(list(zip(tokens,token_pos)),columns=['Token','part_of_speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So</td>\n",
       "      <td>so</td>\n",
       "      <td>Xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christy</td>\n",
       "      <td>christy</td>\n",
       "      <td>Xxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'s</td>\n",
       "      <td>'s</td>\n",
       "      <td>'x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Madison</td>\n",
       "      <td>madison</td>\n",
       "      <td>Xxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tradition</td>\n",
       "      <td>tradition</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>those</td>\n",
       "      <td>those</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lovely</td>\n",
       "      <td>lovely</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>views</td>\n",
       "      <td>view</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lake</td>\n",
       "      <td>lake</td>\n",
       "      <td>Xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Waubesa</td>\n",
       "      <td>waubesa</td>\n",
       "      <td>Xxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>But</td>\n",
       "      <td>but</td>\n",
       "      <td>Xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>place</td>\n",
       "      <td>place</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>track</td>\n",
       "      <td>track</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pony</td>\n",
       "      <td>pony</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>location</td>\n",
       "      <td>location</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>location</td>\n",
       "      <td>location</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>very</td>\n",
       "      <td>very</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>well</td>\n",
       "      <td>well</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>;</td>\n",
       "      <td>;</td>\n",
       "      <td>;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>so</td>\n",
       "      <td>so</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>you</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>'ll</td>\n",
       "      <td>will</td>\n",
       "      <td>'xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>grab</td>\n",
       "      <td>grab</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>table</td>\n",
       "      <td>table</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>outside</td>\n",
       "      <td>outside</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>wait</td>\n",
       "      <td>wait</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>order</td>\n",
       "      <td>order</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>only</td>\n",
       "      <td>only</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>learn</td>\n",
       "      <td>learn</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>you</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>can</td>\n",
       "      <td>can</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>only</td>\n",
       "      <td>only</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>order</td>\n",
       "      <td>order</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>pizza</td>\n",
       "      <td>pizza</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>sandwich</td>\n",
       "      <td>sandwich</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>menu</td>\n",
       "      <td>menu</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token token_lemma token_shape\n",
       "0           So          so          Xx\n",
       "1            I      -PRON-           X\n",
       "2         know        know        xxxx\n",
       "3      Christy     christy       Xxxxx\n",
       "4           's          's          'x\n",
       "5           is          be          xx\n",
       "6            a           a           x\n",
       "7      Madison     madison       Xxxxx\n",
       "8    tradition   tradition        xxxx\n",
       "9         with        with        xxxx\n",
       "10       those       those        xxxx\n",
       "11      lovely      lovely        xxxx\n",
       "12       views        view        xxxx\n",
       "13          of          of          xx\n",
       "14        Lake        lake        Xxxx\n",
       "15     Waubesa     waubesa       Xxxxx\n",
       "16           .           .           .\n",
       "17         But         but         Xxx\n",
       "18        this        this        xxxx\n",
       "19       place       place        xxxx\n",
       "20          is          be          xx\n",
       "21           a           a           x\n",
       "22         one         one         xxx\n",
       "23           -           -           -\n",
       "24       track       track        xxxx\n",
       "25        pony        pony        xxxx\n",
       "26         ...         ...         ...\n",
       "27    location    location        xxxx\n",
       "28           ,           ,           ,\n",
       "29    location    location        xxxx\n",
       "..         ...         ...         ...\n",
       "194       very        very        xxxx\n",
       "195       well        well        xxxx\n",
       "196          ;           ;           ;\n",
       "197                                   \n",
       "198         so          so          xx\n",
       "199        you      -PRON-         xxx\n",
       "200        'll        will         'xx\n",
       "201       grab        grab        xxxx\n",
       "202          a           a           x\n",
       "203      table       table        xxxx\n",
       "204    outside     outside        xxxx\n",
       "205          ,           ,           ,\n",
       "206       wait        wait        xxxx\n",
       "207         to          to          xx\n",
       "208      order       order        xxxx\n",
       "209       only        only        xxxx\n",
       "210         to          to          xx\n",
       "211      learn       learn        xxxx\n",
       "212        you      -PRON-         xxx\n",
       "213        can         can         xxx\n",
       "214       only        only        xxxx\n",
       "215      order       order        xxxx\n",
       "216       from        from        xxxx\n",
       "217        the         the         xxx\n",
       "218      pizza       pizza        xxxx\n",
       "219          /           /           /\n",
       "220   sandwich    sandwich        xxxx\n",
       "221       menu        menu        xxxx\n",
       "222          .           .           .\n",
       "223         \\n          \\n          \\n\n",
       "\n",
       "[224 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "token_lemma = [token.lemma_ for token in parsed_review]\n",
    "token_shape = [token.shape_ for token in parsed_review]\n",
    "\n",
    "pd.DataFrame(list(zip(tokens,token_lemma,token_shape)),\n",
    "               columns=['Token','token_lemma','token_shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>token_type</th>\n",
       "      <th>token_iob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christy</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'s</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Madison</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tradition</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>with</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>those</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lovely</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>views</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>of</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lake</td>\n",
       "      <td>LOC</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Waubesa</td>\n",
       "      <td>LOC</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>But</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>this</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>place</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>one</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>track</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pony</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>location</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>location</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>very</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>well</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>;</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td></td>\n",
       "      <td>NORP</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>so</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>you</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>'ll</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>grab</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>table</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>outside</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>wait</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>to</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>order</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>only</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>to</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>learn</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>you</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>can</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>only</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>order</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>from</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>pizza</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>/</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>sandwich</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>menu</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>\\n</td>\n",
       "      <td>GPE</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token token_type token_iob\n",
       "0           So                    O\n",
       "1            I                    O\n",
       "2         know                    O\n",
       "3      Christy     PERSON         B\n",
       "4           's                    O\n",
       "5           is                    O\n",
       "6            a                    O\n",
       "7      Madison     PERSON         B\n",
       "8    tradition                    O\n",
       "9         with                    O\n",
       "10       those                    O\n",
       "11      lovely                    O\n",
       "12       views                    O\n",
       "13          of                    O\n",
       "14        Lake        LOC         B\n",
       "15     Waubesa        LOC         I\n",
       "16           .                    O\n",
       "17         But                    O\n",
       "18        this                    O\n",
       "19       place                    O\n",
       "20          is                    O\n",
       "21           a                    O\n",
       "22         one   CARDINAL         B\n",
       "23           -                    O\n",
       "24       track                    O\n",
       "25        pony                    O\n",
       "26         ...                    O\n",
       "27    location                    O\n",
       "28           ,                    O\n",
       "29    location                    O\n",
       "..         ...        ...       ...\n",
       "194       very                    O\n",
       "195       well                    O\n",
       "196          ;                    O\n",
       "197                  NORP         B\n",
       "198         so                    O\n",
       "199        you                    O\n",
       "200        'll                    O\n",
       "201       grab                    O\n",
       "202          a                    O\n",
       "203      table                    O\n",
       "204    outside                    O\n",
       "205          ,                    O\n",
       "206       wait                    O\n",
       "207         to                    O\n",
       "208      order                    O\n",
       "209       only                    O\n",
       "210         to                    O\n",
       "211      learn                    O\n",
       "212        you                    O\n",
       "213        can                    O\n",
       "214       only                    O\n",
       "215      order                    O\n",
       "216       from                    O\n",
       "217        the                    O\n",
       "218      pizza                    O\n",
       "219          /                    O\n",
       "220   sandwich                    O\n",
       "221       menu                    O\n",
       "222          .                    O\n",
       "223         \\n        GPE         B\n",
       "\n",
       "[224 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token-level analysis\n",
    "token_entity_type = [token.ent_type_ for token in parsed_review]\n",
    "token_entity_iob  = [token.ent_iob_ for token in parsed_review]\n",
    "pd.DataFrame(list(zip(tokens,token_entity_type,token_entity_iob)),\n",
    "             columns=['Token','token_type','token_iob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* stopword\n",
    "* punctuation\n",
    "* whitespace\n",
    "* a number\n",
    "* spacy default vocaluary ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Log proba</th>\n",
       "      <th>stop ?</th>\n",
       "      <th>punct ?</th>\n",
       "      <th>whitespace ?</th>\n",
       "      <th>number ?</th>\n",
       "      <th>out of vocab ?</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>-PRON-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christy</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>christy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'s</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>'s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Madison</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tradition</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>with</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>those</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>those</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lovely</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>views</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>of</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lake</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>lake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Waubesa</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>waubesa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>But</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>this</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>place</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>one</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>track</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pony</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>pony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>...</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>location</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>,</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>location</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>very</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>well</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>;</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td></td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>so</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>you</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>-PRON-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>'ll</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>grab</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>grab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>a</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>table</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>outside</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>outside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>,</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>wait</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>to</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>order</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>only</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>to</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>learn</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>you</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>-PRON-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>can</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>only</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>order</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>from</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>the</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>pizza</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>pizza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>/</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>sandwich</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>menu</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>.</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>\\n</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token  Log proba stop ? punct ? whitespace ? number ? out of vocab ?  \\\n",
       "0           So      -20.0                                                 Yes   \n",
       "1            I      -20.0                                                 Yes   \n",
       "2         know      -20.0                                                 Yes   \n",
       "3      Christy      -20.0                                                 Yes   \n",
       "4           's      -20.0                                                 Yes   \n",
       "5           is      -20.0    Yes                                          Yes   \n",
       "6            a      -20.0    Yes                                          Yes   \n",
       "7      Madison      -20.0                                                 Yes   \n",
       "8    tradition      -20.0                                                 Yes   \n",
       "9         with      -20.0    Yes                                          Yes   \n",
       "10       those      -20.0    Yes                                          Yes   \n",
       "11      lovely      -20.0                                                 Yes   \n",
       "12       views      -20.0                                                 Yes   \n",
       "13          of      -20.0    Yes                                          Yes   \n",
       "14        Lake      -20.0                                                 Yes   \n",
       "15     Waubesa      -20.0                                                 Yes   \n",
       "16           .      -20.0            Yes                                  Yes   \n",
       "17         But      -20.0                                                 Yes   \n",
       "18        this      -20.0    Yes                                          Yes   \n",
       "19       place      -20.0                                                 Yes   \n",
       "20          is      -20.0    Yes                                          Yes   \n",
       "21           a      -20.0    Yes                                          Yes   \n",
       "22         one      -20.0    Yes                           Yes            Yes   \n",
       "23           -      -20.0            Yes                                  Yes   \n",
       "24       track      -20.0                                                 Yes   \n",
       "25        pony      -20.0                                                 Yes   \n",
       "26         ...      -20.0            Yes                                  Yes   \n",
       "27    location      -20.0                                                 Yes   \n",
       "28           ,      -20.0            Yes                                  Yes   \n",
       "29    location      -20.0                                                 Yes   \n",
       "..         ...        ...    ...     ...          ...      ...            ...   \n",
       "194       very      -20.0    Yes                                          Yes   \n",
       "195       well      -20.0    Yes                                          Yes   \n",
       "196          ;      -20.0            Yes                                  Yes   \n",
       "197                 -20.0                         Yes                     Yes   \n",
       "198         so      -20.0    Yes                                          Yes   \n",
       "199        you      -20.0    Yes                                          Yes   \n",
       "200        'll      -20.0                                                 Yes   \n",
       "201       grab      -20.0                                                 Yes   \n",
       "202          a      -20.0    Yes                                          Yes   \n",
       "203      table      -20.0                                                 Yes   \n",
       "204    outside      -20.0                                                 Yes   \n",
       "205          ,      -20.0            Yes                                  Yes   \n",
       "206       wait      -20.0                                                 Yes   \n",
       "207         to      -20.0    Yes                                          Yes   \n",
       "208      order      -20.0                                                 Yes   \n",
       "209       only      -20.0    Yes                                          Yes   \n",
       "210         to      -20.0    Yes                                          Yes   \n",
       "211      learn      -20.0                                                 Yes   \n",
       "212        you      -20.0    Yes                                          Yes   \n",
       "213        can      -20.0    Yes                                          Yes   \n",
       "214       only      -20.0    Yes                                          Yes   \n",
       "215      order      -20.0                                                 Yes   \n",
       "216       from      -20.0    Yes                                          Yes   \n",
       "217        the      -20.0    Yes                                          Yes   \n",
       "218      pizza      -20.0                                                 Yes   \n",
       "219          /      -20.0            Yes                                  Yes   \n",
       "220   sandwich      -20.0                                                 Yes   \n",
       "221       menu      -20.0                                                 Yes   \n",
       "222          .      -20.0            Yes                                  Yes   \n",
       "223         \\n      -20.0                         Yes                     Yes   \n",
       "\n",
       "         Lemma  \n",
       "0           so  \n",
       "1       -PRON-  \n",
       "2         know  \n",
       "3      christy  \n",
       "4           's  \n",
       "5           be  \n",
       "6            a  \n",
       "7      madison  \n",
       "8    tradition  \n",
       "9         with  \n",
       "10       those  \n",
       "11      lovely  \n",
       "12        view  \n",
       "13          of  \n",
       "14        lake  \n",
       "15     waubesa  \n",
       "16           .  \n",
       "17         but  \n",
       "18        this  \n",
       "19       place  \n",
       "20          be  \n",
       "21           a  \n",
       "22         one  \n",
       "23           -  \n",
       "24       track  \n",
       "25        pony  \n",
       "26         ...  \n",
       "27    location  \n",
       "28           ,  \n",
       "29    location  \n",
       "..         ...  \n",
       "194       very  \n",
       "195       well  \n",
       "196          ;  \n",
       "197             \n",
       "198         so  \n",
       "199     -PRON-  \n",
       "200       will  \n",
       "201       grab  \n",
       "202          a  \n",
       "203      table  \n",
       "204    outside  \n",
       "205          ,  \n",
       "206       wait  \n",
       "207         to  \n",
       "208      order  \n",
       "209       only  \n",
       "210         to  \n",
       "211      learn  \n",
       "212     -PRON-  \n",
       "213        can  \n",
       "214       only  \n",
       "215      order  \n",
       "216       from  \n",
       "217        the  \n",
       "218      pizza  \n",
       "219          /  \n",
       "220   sandwich  \n",
       "221       menu  \n",
       "222          .  \n",
       "223         \\n  \n",
       "\n",
       "[224 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_attr = [(token.text,\n",
    "               token.prob,\n",
    "               token.is_stop,\n",
    "               token.is_punct,\n",
    "               token.is_space,\n",
    "               token.like_num,\n",
    "               token.is_oov,\n",
    "               token.lemma_)\n",
    "             for token in parsed_review]\n",
    "df = pd.DataFrame(token_attr,columns=['Token','Log proba','stop ?','punct ?',\n",
    "                                 'whitespace ?','number ?','out of vocab ?','Lemma'])\n",
    "df.loc[:,\"stop ?\" : \"out of vocab ?\"] = \\\n",
    "df.loc[:,\"stop ?\" : \"out of vocab ?\"].applymap(lambda x: 'Yes' if x else '')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def punct_space(token):\n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def line_review(filename):\n",
    "    with codecs.open(filename,encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            yield review\n",
    "            \n",
    "def lematized_sentence_corpus(filename):\n",
    "    for parsed_review in nlp.pipe(line_review(filename),n_threads=4,batch_size=10000):\n",
    "        for sent in parsed_review.sents:\n",
    "            yield u' '.join([token.lemma_ for token in sent if not punct_space(token)])\n",
    "\n",
    "unigrams_sentences_filepath = os.path.join(data_directory,'unigram_sents_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "count = 0\n",
    "with codecs.open(unigrams_sentences_filepath,'w',encoding='utf_8') as f:\n",
    "    for sent in lematized_sentence_corpus(review_txt_filepath):\n",
    "        f.write(sent + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoking gensim\n",
    "unigram_sentences = LineSentence(unigrams_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON- have find a few great place there but no food especially asian have actually be that great until fin\n",
      "-PRON- go here on a sunday evening and be concern -PRON- would not be open but -PRON- be until 10 pm\n",
      "-PRON- be greet in japanese and seat immediately by -PRON- extremely friendly and attentive server\n",
      "food be a bit on the pricey side but without there be much competition in term of izakaya in oakville -PRON- be not surprised and -PRON- do not break the bank\n",
      "personal favorite be the selection of fish for three see picture so beautiful and the eastern style caesar who would not love a drink with a crab leg in it!).overall i be super impressed with the quality and variety of food as well as the service\n",
      "-PRON- could not recommend fin enough to those starve for a bit of asian food in oakville!disclaimer if -PRON- be from toronto and eat izakaya all the time this may be a touch pricey for -PRON-\n",
      "warn\n",
      "this be not the same fin as before sell to new owner\n",
      "super dry pull pork rice burger and stale sashimi salad and go bad chicken skewer be the 3 dish order\n",
      "-PRON- give 15 tip that the owner dare to ask for such food and service smile back at the owner and say see -PRON- next time not\n"
     ]
    }
   ],
   "source": [
    "for unigram_sents in it.islice(unigram_sentences,210,220):\n",
    "    print(\" \".join(unigram_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = Phrases(unigram_sentences)\n",
    "bigram_model.save('bigram_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "#bigram_model = Phrases.load('bigram_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-PRON-', 'have', 'find', 'a', 'few', 'great', 'place', 'there', 'but', 'no', 'food', 'especially', 'asian', 'have', 'actually', 'be', 'that', 'great', 'until', 'fin']\n",
      "['-PRON-', 'go', 'here', 'on', 'a', 'sunday', 'evening', 'and', 'be', 'concern', '-PRON-', 'would', 'not', 'be', 'open', 'but', '-PRON-', 'be', 'until', '10', 'pm']\n",
      "['-PRON-', 'be', 'greet', 'in', 'japanese', 'and', 'seat_immediately', 'by', '-PRON-', 'extremely', 'friendly', 'and', 'attentive', 'server']\n",
      "['food', 'be', 'a', 'bit', 'on', 'the', 'pricey', 'side', 'but', 'without', 'there', 'be', 'much', 'competition', 'in', 'term', 'of', 'izakaya', 'in', 'oakville', '-PRON-', 'be', 'not', 'surprised', 'and', '-PRON-', 'do', 'not', 'break', 'the', 'bank']\n",
      "['personal_favorite', 'be', 'the', 'selection', 'of', 'fish', 'for', 'three', 'see', 'picture', 'so', 'beautiful', 'and', 'the', 'eastern', 'style', 'caesar', 'who', 'would', 'not', 'love', 'a', 'drink', 'with', 'a', 'crab_leg', 'in', 'it!).overall', 'i', 'be', 'super', 'impressed', 'with', 'the', 'quality', 'and', 'variety', 'of', 'food', 'as', 'well', 'as', 'the', 'service']\n",
      "['-PRON-', 'could', 'not', 'recommend', 'fin', 'enough', 'to', 'those', 'starve', 'for', 'a', 'bit', 'of', 'asian', 'food', 'in', 'oakville!disclaimer', 'if', '-PRON-', 'be', 'from', 'toronto', 'and', 'eat', 'izakaya', 'all', 'the', 'time', 'this', 'may', 'be', 'a', 'touch', 'pricey', 'for', '-PRON-']\n",
      "['warn']\n",
      "['this', 'be', 'not', 'the', 'same', 'fin', 'as', 'before', 'sell', 'to', 'new', 'owner']\n",
      "['super', 'dry', 'pull_pork', 'rice', 'burger', 'and', 'stale', 'sashimi', 'salad', 'and', 'go', 'bad', 'chicken', 'skewer', 'be', 'the', '3', 'dish', 'order']\n",
      "['-PRON-', 'give', '15', 'tip', 'that', 'the', 'owner', 'dare', 'to', 'ask', 'for', 'such', 'food', 'and', 'service', 'smile', 'back', 'at', 'the', 'owner', 'and', 'say', 'see', '-PRON-', 'next', 'time', 'not']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleksandr/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "for unigram_sents in it.islice(unigram_sentences,210,220):\n",
    "    print(bigram_model[unigram_sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have a trained phrase model for words pairs, <br/> let's apply it to the review sentences data and explore the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleksandr/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "bigram_sententes_filepath = os.path.join(data_directory,'bigram_sentences_all.txt')\n",
    "\n",
    "with codecs.open(bigram_sententes_filepath,'w',encoding='utf-8') as f:\n",
    "    for sent in unigram_sentences:\n",
    "        bigram_sent = \" \".join(bigram_model[sent])\n",
    "        f.write(bigram_sent + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON- have find a few great place there but no food especially asian have actually be that great until fin\n",
      "-PRON- go here on a sunday evening and be concern -PRON- would not be open but -PRON- be until 10 pm\n",
      "-PRON- be greet in japanese and seat_immediately by -PRON- extremely friendly and attentive server\n",
      "food be a bit on the pricey side but without there be much competition in term of izakaya in oakville -PRON- be not surprised and -PRON- do not break the bank\n",
      "personal_favorite be the selection of fish for three see picture so beautiful and the eastern style caesar who would not love a drink with a crab_leg in it!).overall i be super impressed with the quality and variety of food as well as the service\n",
      "-PRON- could not recommend fin enough to those starve for a bit of asian food in oakville!disclaimer if -PRON- be from toronto and eat izakaya all the time this may be a touch pricey for -PRON-\n",
      "warn\n",
      "this be not the same fin as before sell to new owner\n",
      "super dry pull_pork rice burger and stale sashimi salad and go bad chicken skewer be the 3 dish order\n",
      "-PRON- give 15 tip that the owner dare to ask for such food and service smile back at the owner and say see -PRON- next time not\n"
     ]
    }
   ],
   "source": [
    "bigram_sentences = LineSentence(bigram_sententes_filepath)\n",
    "for sent in it.islice(bigram_sentences,210,220):\n",
    "    print(\" \".join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply again to build trigram model\n",
    "trigram_model = Phrases(bigram_sentences)\n",
    "trigram_model.save('trigram_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trigram_model = Phrases.load('trigram_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # These are the usual ipython objects, including this one you are creating\n",
    "# ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# # Get a sorted list of the objects and their sizes\n",
    "# sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') \n",
    "#         and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences_filepath = os.path.join(data_directory,'trigram_sentences_all.txt')\n",
    "\n",
    "with codecs.open(trigram_sentences_filepath,'w',encoding='utf-8') as file:\n",
    "    for sent in bigram_sentences:\n",
    "        trigram_sent = \" \".join(trigram_model[sent])\n",
    "        file.write(trigram_sent + '\\n')\n",
    "    \n",
    "\n",
    "trigram_sentences = LineSentence(trigram_sentences_filepath)\n",
    "for sent in it.islice(trigram_sentences,240,250):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final step of data preprocessing : <br/>run the complete text of the reviews through a pipeline that applies our text normalization and phrase models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_reviews_filespath = os.path.join(data_directory,\n",
    "                                        'trigram_transformed_reviews_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleksandr/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11h 10min 40s, sys: 32min 3s, total: 11h 42min 43s\n",
      "Wall time: 3h 48min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with codecs.open(trigram_reviews_filespath,'w',encoding='utf_8') as f:\n",
    "    for parsed_review in nlp.pipe(line_review(review_txt_filepath),batch_size=10000,n_threads=4):\n",
    "        # lemmatize the text, removing punctuation and whitespace\n",
    "        unigram_review = [token.lemma_ for token in parsed_review if not punct_space(token)]\n",
    "        \n",
    "        # apply models\n",
    "        bigram_review = bigram_model[unigram_review]\n",
    "        trigram_review = trigram_model[bigram_review]\n",
    "        \n",
    "        # remove any remaining stopwords\n",
    "        trigram_review = [term for term in trigram_review if term not in spacy.lang.en.STOP_WORDS]\n",
    "\n",
    "        # write the tramsformed review as a line in the new line\n",
    "        trigram_review = \" \".join(trigram_review)\n",
    "        f.write(trigram_review + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "\n",
      "This is my 9 year olds review.     Hamburgers are great and the cheese curds are awesome.   There is a Great Lake View\n",
      "\n",
      "-------\n",
      "\n",
      "Transformed:\n",
      "\n",
      "-PRON- 9 year_old review hamburger great cheese_curd awesome great lake_view\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original:' + '\\n')\n",
    "\n",
    "for review in it.islice(line_review(review_txt_filepath),0,1):\n",
    "    print(review)\n",
    "    \n",
    "print('-------' + '\\n')\n",
    "print('Transformed:'+'\\n')\n",
    "with codecs.open(trigram_reviews_filespath,encoding='utf_8') as f:\n",
    "    for review in it.islice(f,0,1):\n",
    "        print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Topic modeling with Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: failed\n",
      "\n",
      "UnsatisfiableError: The following specifications were found to be in conflict:\n",
      "  - lightgbm\n",
      "  - pyldavis\n",
      "Use \"conda info <package>\" to see the dependencies for each package.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c memex pyldavis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the dictionary\n",
    "\n",
    "trigram_dict_filepath = os.path.join(data_directory,'trigram_dict_all.dict')\n",
    "trigram_reviews = LineSentence(trigram_reviews_filespath)\n",
    "\n",
    "trigram_dict = Dictionary(trigram_reviews)\n",
    "\n",
    "trigram_dict.filter_extremes(no_below=10,no_above=0.4)\n",
    "\n",
    "trigram_dict.compactify()\n",
    "\n",
    "trigram_dict.save(trigram_dict_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words model\n",
    "trigram_bow_filepath = os.path.join(data_directory,'trigram_bow_corpus_all.mm')\n",
    "\n",
    "def trigram_bow_generator(filepath):\n",
    "    for review in LineSentence(filepath):\n",
    "        yield trigram_dict.doc2bow(review)\n",
    "\n",
    "# Generate bow for all reviews and save them as a matrix\n",
    "\n",
    "%%time\n",
    "MmCorpus.serialize(trigram_bow_filepath,trigram_bow_generator(trigram_reviews_filespath))\n",
    "\n",
    "\n",
    "trigram_bow_corpus = MmCorpus(trigram_bow_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_filepath = os.path.join(data_directory,'lda_model_all')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    lda = LdaMulticore(trigram_bow_corpus,\n",
    "                       num_topics=50,\n",
    "                       id2word=trigram_dict,\n",
    "                       workers=3)\n",
    "\n",
    "lda.save(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-250404219.79660738"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.bound(trigram_bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_topic(topic_number, topn = 25):\n",
    "    print('{:20} {}'.format('term','frequency') + '\\n')\n",
    "    for term, frequency in lda.show_topic(topic_number, topn=topn):\n",
    "        print('{:20} {:.3f}'.format(term,round(frequency,3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "mom                  0.048\n",
      "brother              0.023\n",
      "dad                  0.023\n",
      "like                 0.009\n",
      "parent               0.009\n",
      "morels               0.008\n",
      "bachi                0.008\n",
      "'s                   0.007\n",
      "law                  0.007\n",
      "sister               0.007\n",
      "mother               0.007\n",
      "father               0.007\n",
      "calzone              0.006\n",
      "cowboy               0.006\n",
      "home                 0.005\n",
      "year_old             0.005\n",
      "know                 0.005\n",
      "tamale               0.005\n",
      "ball                 0.004\n",
      "way                  0.004\n",
      "think                0.004\n",
      "treasure_island      0.004\n",
      "22                   0.003\n",
      "jersey               0.003\n",
      "claim                0.003\n"
     ]
    }
   ],
   "source": [
    "explore_topic(topic_number=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleksandr/anaconda3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda,trigram_bow_corpus,trigram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pyLDAvis.prepared_data_to_html(LDAvis_prepared)\n",
    "\n",
    "with open('test.html','w') as f:\n",
    "    f.write(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_review(k):\n",
    "    return list(it.islice(line_review(review_txt_filepath), k,k+1))[0]\n",
    "\n",
    "def lda_description(review_text, min_topic_freq=0.05):\n",
    "    parsed_review = nlp(review_text)\n",
    "    unig_rev = [token.lemma_ for token in parsed_review if not punct_space(token)]\n",
    "    bigr_rev = bigram_model[unig_rev]\n",
    "    trig_rev = trigram_model[bigr_rev]\n",
    "    trig_rev = [term for term in trig_rev if not term in spacy.lang.en.STOP_WORDS]\n",
    "    rev_bow = trigram_dict.doc2bow(trig_rev)\n",
    "    rev_lda = lda[rev_bow]\n",
    "    rev_lda = sorted(rev_lda, key = lambda x: - x[1])\n",
    "    \n",
    "    for k, freq in rev_lda:\n",
    "        if freq < min_topic_freq:\n",
    "            break\n",
    "        print('{:25} {}'.format(k,round(freq, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So I know Christy's is a Madison tradition with those lovely views of Lake Waubesa. But this place is a one-track pony... location, location, location. This is a family-owned bar/restaurant and the owners know they have a captive audience. The beer is cold and the food is average, but the service is atrocious. On a recent beautiful Saturday afternoon, there were only two servers for the outside seating area.  There's no host, so we (4 adults and 1 kid) sat at a picnic table and proceeded to wait at least 10 minutes to no avail. We eventually went inside to order drinks and lunch. At no time during our visit did a server ever approach our table. I'd certainly be inclined to write off this awful experience to a bad day or poor staffing, but unfortunately this is more the rule rather than exception. One really weird thing is the Friday Fish Fry that features a special menu available ONLY inside, this isn't communicated very well;  so you'll grab a table outside, wait to order only to learn you can only order from the pizza/sandwich menu.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_rev = get_sample_review(50)\n",
    "print(sample_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       25 0.3720000088214874\n",
      "                       28 0.14499999582767487\n",
      "                       33 0.0860000029206276\n",
      "                       19 0.08399999886751175\n",
      "                       47 0.0729999989271164\n",
      "                       42 0.057999998331069946\n",
      "                       14 0.05400000140070915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleksandr/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "lda_description(sample_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "trigram_sents = LineSentence(trigram_sentences_filepath)\n",
    "word2vec_model_path = os.path.join(data_directory,'word2vec_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "food2vec = Word2Vec(trigram_sents,size=100,window=5,min_count=20,sg=1)\n",
    "food2vec.save(word2vec_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0;31m# Things that don't have seek will trigger an exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-65b45020c011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfood2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigram_sents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfood2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_train_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the sentences argument. Try an iterator.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             self.train(\n\u001b[1;32m    337\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \"\"\"\n\u001b[1;32m    479\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[0;32m--> 480\u001b[0;31m             sentences, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         report_values = self.vocabulary.prepare_vocab(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0mchecked_string_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1075\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m                         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(i)\n",
    "    food2vec.train(trigram_sents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
