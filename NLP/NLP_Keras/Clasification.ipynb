{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Embedding, Conv1D, SpatialDropout1D, GlobalMaxPool1D, SimpleRNN, LSTM, MaxPooling1D\n",
    "from keras.layers import Input, concatenate\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_output/dense'\n",
    "output_dir_conv = 'model_output/conv'\n",
    "output_dir_rnn = 'model_output/rnn'\n",
    "output_dir_lstm = 'model_output/lstm'\n",
    "\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "n_dim = 64\n",
    "n_unique_words = 10000\n",
    "n_words_toskip = 50\n",
    "max_review_length = 100\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2\n",
    "\n",
    "n_dense = 256\n",
    "dropout = 0.2\n",
    "\n",
    "n_conv = 256\n",
    "k_conv = 3\n",
    "\n",
    "n_rnn = 256\n",
    "k_conv = 3\n",
    "\n",
    "n_lstm = 256\n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_valid,y_valid) = imdb.load_data(num_words=n_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rstore words from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "word_index ={k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"PAD\"] = 0\n",
    "word_index[\"START\"] = 1\n",
    "word_index['UNK'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {v:k for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"UNK UNK UNK UNK UNK brilliant casting location scenery story direction everyone's really suited UNK part UNK played UNK UNK could UNK imagine being there robert UNK UNK UNK amazing actor UNK now UNK same being director UNK father came UNK UNK same scottish island UNK myself UNK UNK loved UNK fact there UNK UNK real connection UNK UNK UNK UNK witty remarks throughout UNK UNK were great UNK UNK UNK brilliant UNK much UNK UNK bought UNK UNK UNK soon UNK UNK UNK released UNK UNK UNK would recommend UNK UNK everyone UNK watch UNK UNK fly UNK UNK amazing really cried UNK UNK end UNK UNK UNK sad UNK UNK know what UNK say UNK UNK cry UNK UNK UNK UNK must UNK been good UNK UNK definitely UNK also UNK UNK UNK two little UNK UNK played UNK UNK UNK norman UNK paul UNK were UNK brilliant children UNK often left UNK UNK UNK UNK list UNK think because UNK stars UNK play them UNK grown up UNK such UNK big UNK UNK UNK whole UNK UNK these children UNK amazing UNK should UNK UNK UNK what UNK UNK done don't UNK think UNK whole story UNK UNK lovely because UNK UNK true UNK UNK someone's life after UNK UNK UNK UNK UNK us UNK\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([index_word[indx] for indx in x_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train,maxlen=max_review_length,padding=pad_type,truncating=trunc_type)\n",
    "x_valid = pad_sequences(x_valid,maxlen=max_review_length,padding=pad_type,truncating=trunc_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1415    2    2    2    2  215    2   77   52    2    2  407    2   82\n",
      "    2    2    2  107  117    2    2  256    2    2    2 3766    2  723\n",
      "    2   71    2  530  476    2  400  317    2    2    2    2 1029    2\n",
      "  104   88    2  381    2  297   98    2 2071   56    2  141    2  194\n",
      "    2    2    2  226    2    2  134  476    2  480    2  144    2    2\n",
      "    2   51    2    2  224   92    2  104    2  226   65    2    2 1334\n",
      "   88    2    2  283    2    2 4472  113  103    2    2    2    2    2\n",
      "  178    2]\n",
      "[ 163    2 3215    2    2 1153    2  194  775    2    2    2  349 2637\n",
      "  148  605    2    2    2  123  125   68    2    2    2  349  165 4362\n",
      "   98    2    2  228    2    2    2 1157    2  299  120    2  120  174\n",
      "    2  220  175  136   50    2 4373  228    2    2    2  656  245 2350\n",
      "    2    2    2  131  152  491    2    2    2    2 1212    2    2    2\n",
      "  371   78    2  625   64 1382    2    2  168  145    2    2 1690    2\n",
      "    2    2 1355    2    2    2   52  154  462    2   89   78  285    2\n",
      "  145   95]\n",
      "[1301    2 1873    2   89   78    2   66    2    2  360    2    2   58\n",
      "  316  334    2    2 1716    2  645  662    2  257   85 1200    2 1228\n",
      " 2578   83   68 3912    2    2  165 1539  278    2   69    2  780    2\n",
      "  106    2    2 1338    2    2    2    2  215    2  610    2    2   87\n",
      "  326    2 2300    2    2    2    2  272    2   57    2    2    2    2\n",
      "    2    2 2307   51    2  170    2  595  116  595 1352    2  191   79\n",
      "  638   89    2    2    2    2  106  607  624    2  534    2  227    2\n",
      "  129  113]\n",
      "[   2    2    2  188 1076 3222    2    2    2    2 2348  537    2   53\n",
      "  537    2   82    2    2    2    2    2  280    2  219    2    2  431\n",
      "  758  859    2  953 1052    2    2    2    2   94    2    2  238   60\n",
      "    2    2    2  804    2    2    2    2  132    2   67    2    2    2\n",
      "    2  283    2    2    2    2    2  242  955    2    2  279    2    2\n",
      "    2 1685  195    2  238   60  796    2    2  671    2 2804    2    2\n",
      "  559  154  888    2  726   50    2    2    2    2  566    2  579    2\n",
      "   64 2574]\n",
      "[   2    2  131 2073  249  114  249  229  249    2    2    2  126  110\n",
      "    2  473    2  569   61  419   56  429    2 1513    2    2  534   95\n",
      "  474  570    2    2  124  138   88    2  421 1543   52  725    2   61\n",
      "  419    2    2 1571    2 1543    2    2    2    2    2  296    2 3524\n",
      "    2    2  421  128   74  233  334  207  126  224    2  562  298 2167\n",
      " 1272    2 2601    2  516  988    2    2   79  120    2  595    2  784\n",
      "    2 3171    2  165  170  143    2    2    2    2    2  226  251    2\n",
      "   61  113]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    2  778  128   74    2  630  163    2    2 1766    2 1051    2\n",
      "    2   85  156    2    2  148  139  121  664  665    2    2 1361  173\n",
      "    2  749    2    2 3804    2    2  226   65    2    2  127    2    2\n",
      "    2    2]\n"
     ]
    }
   ],
   "source": [
    "for rev in x_train[:6]:\n",
    "    print(rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words,n_dim,input_length=max_review_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_dense,activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 64)           320000    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 729,729\n",
      "Trainable params: 729,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modelchekpoints = ModelCheckpoint(filepath=output_dir+'weights.{epoch:02d}.hdf5')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.2884 - acc: 0.8858 - val_loss: 0.3422 - val_acc: 0.8503\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 68us/step - loss: 0.1277 - acc: 0.9614 - val_loss: 0.4179 - val_acc: 0.8355\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0283 - acc: 0.9944 - val_loss: 0.5436 - val_acc: 0.8294\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.0076 - acc: 0.9993 - val_loss: 0.6102 - val_acc: 0.8344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3e684be0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_valid,y_valid),callbacks=[modelchekpoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_output'+'/denseweights.02.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict_proba(x_valid)\n",
    "\n",
    "roc_auc_score(y_valid,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Spatial 1D version of Dropout.\n",
       "\n",
       "This version performs the same function as Dropout, however it drops\n",
       "entire 1D feature maps instead of individual elements. If adjacent frames\n",
       "within feature maps are strongly correlated (as is normally the case in\n",
       "early convolution layers) then regular dropout will not regularize the\n",
       "activations and will otherwise just result in an effective learning rate\n",
       "decrease. In this case, SpatialDropout1D will help promote independence\n",
       "between feature maps and should be used instead.\n",
       "\n",
       "# Arguments\n",
       "    rate: float between 0 and 1. Fraction of the input units to drop.\n",
       "\n",
       "# Input shape\n",
       "    3D tensor with shape:\n",
       "    `(samples, timesteps, channels)`\n",
       "\n",
       "# Output shape\n",
       "    Same as input\n",
       "\n",
       "# References\n",
       "    - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)\n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.6/site-packages/keras/layers/core.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SpatialDropout1D?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words,n_dim,input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "#model.add(Flatten())\n",
    "model.add(Conv1D(n_conv,k_conv, activation='relu'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(n_dense,activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 64)           320000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 400, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 398, 256)          49408     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 435,457\n",
      "Trainable params: 435,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "modelchekpoints = ModelCheckpoint(filepath=output_dir_conv+'weights.{epoch:02d}.hdf5')\n",
    "if not os.path.exists(output_dir_conv):\n",
    "    os.makedirs(output_dir_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 80s 3ms/step - loss: 0.4900 - acc: 0.7461 - val_loss: 0.2979 - val_acc: 0.8747\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 79s 3ms/step - loss: 0.2565 - acc: 0.8965 - val_loss: 0.2720 - val_acc: 0.8835\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 81s 3ms/step - loss: 0.1743 - acc: 0.9326 - val_loss: 0.2583 - val_acc: 0.8950\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 80s 3ms/step - loss: 0.1169 - acc: 0.9605 - val_loss: 0.2780 - val_acc: 0.8934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a30a7f198>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_valid,y_valid),callbacks=[modelchekpoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9606502368000001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict_proba(x_valid)\n",
    "roc_auc_score(y_valid,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words,n_dim,input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(SimpleRNN(n_rnn, dropout=dropout))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 256)               82176     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 722,433\n",
      "Trainable params: 722,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "modelchekpoints = ModelCheckpoint(filepath=output_dir_rnn+'weights.{epoch:02d}.hdf5')\n",
    "if not os.path.exists(output_dir_rnn):\n",
    "    os.makedirs(output_dir_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/16\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.7074 - acc: 0.5124 - val_loss: 0.7006 - val_acc: 0.5088\n",
      "Epoch 2/16\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.6871 - acc: 0.5360 - val_loss: 0.6947 - val_acc: 0.5407\n",
      "Epoch 3/16\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.6127 - acc: 0.6487 - val_loss: 0.5571 - val_acc: 0.7182\n",
      "Epoch 4/16\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.4964 - acc: 0.7582 - val_loss: 0.5149 - val_acc: 0.7846\n",
      "Epoch 5/16\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4165 - acc: 0.8188 - val_loss: 0.4607 - val_acc: 0.8057\n",
      "Epoch 6/16\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.3836 - acc: 0.8354 - val_loss: 0.4659 - val_acc: 0.8007\n",
      "Epoch 7/16\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.3574 - acc: 0.8480 - val_loss: 0.4632 - val_acc: 0.8063\n",
      "Epoch 8/16\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.3007 - acc: 0.8790 - val_loss: 0.5347 - val_acc: 0.7307\n",
      "Epoch 9/16\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.5208 - acc: 0.7308 - val_loss: 0.6585 - val_acc: 0.6034\n",
      "Epoch 10/16\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.5457 - acc: 0.7129 - val_loss: 0.7794 - val_acc: 0.6546\n",
      "Epoch 11/16\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.5375 - acc: 0.7270 - val_loss: 0.8167 - val_acc: 0.6289\n",
      "Epoch 12/16\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.4667 - acc: 0.7805 - val_loss: 0.6581 - val_acc: 0.7160\n",
      "Epoch 13/16\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4205 - acc: 0.8198 - val_loss: 0.5344 - val_acc: 0.7652\n",
      "Epoch 14/16\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4433 - acc: 0.7920 - val_loss: 0.6128 - val_acc: 0.7156\n",
      "Epoch 15/16\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4545 - acc: 0.7829 - val_loss: 0.6447 - val_acc: 0.6182\n",
      "Epoch 16/16\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4805 - acc: 0.7744 - val_loss: 0.6207 - val_acc: 0.6512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a40ffb240>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_valid,y_valid),callbacks=[modelchekpoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_output'+'/rnnweights.08.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8088009312000001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict_proba(x_valid)\n",
    "roc_auc_score(y_valid,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mconv\u001b[m\u001b[m                 denseweights.04.hdf5 rnnweights.08.hdf5\n",
      "convweights.01.hdf5  \u001b[34mrnn\u001b[m\u001b[m                  rnnweights.09.hdf5\n",
      "convweights.02.hdf5  rnnweights.01.hdf5   rnnweights.10.hdf5\n",
      "convweights.03.hdf5  rnnweights.02.hdf5   rnnweights.11.hdf5\n",
      "convweights.04.hdf5  rnnweights.03.hdf5   rnnweights.12.hdf5\n",
      "\u001b[34mdense\u001b[m\u001b[m                rnnweights.04.hdf5   rnnweights.13.hdf5\n",
      "denseweights.01.hdf5 rnnweights.05.hdf5   rnnweights.14.hdf5\n",
      "denseweights.02.hdf5 rnnweights.06.hdf5   rnnweights.15.hdf5\n",
      "denseweights.03.hdf5 rnnweights.07.hdf5   rnnweights.16.hdf5\n"
     ]
    }
   ],
   "source": [
    "!ls model_output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words,n_dim,input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(LSTM(n_lstm, dropout=drop_lstm))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               328704    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 968,961\n",
      "Trainable params: 968,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "modelchekpoints = ModelCheckpoint(filepath=output_dir_lstm+'weights.{epoch:02d}.hdf5')\n",
    "if not os.path.exists(output_dir_lstm):\n",
    "    os.makedirs(output_dir_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 101s 4ms/step - loss: 0.5455 - acc: 0.7128 - val_loss: 0.3861 - val_acc: 0.8304\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.3142 - acc: 0.8695 - val_loss: 0.3450 - val_acc: 0.8502\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 103s 4ms/step - loss: 0.2433 - acc: 0.9038 - val_loss: 0.3923 - val_acc: 0.8408\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 105s 4ms/step - loss: 0.2040 - acc: 0.9206 - val_loss: 0.3652 - val_acc: 0.8453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2a0b3240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_valid,y_valid),callbacks=[modelchekpoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9242907360000001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict_proba(x_valid)\n",
    "roc_auc_score(y_valid,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_unique_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1ce8c48e317b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_unique_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_review_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_unique_words' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words,n_dim,input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words,n_dim,input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution-LSTM stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words,n_dim,input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Conv1D(n_conv,k_conv, activation='relu'))\n",
    "model.add(MaxPooling1D(mp_size))\n",
    "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(100,),dtype='int16',name='input')\n",
    "embedding_layer = Embedding(5000, 128, input_length=100,name='embedding')(input_layer)\n",
    "drop_embed_layer = SpatialDropout1D(0.2,name='drop_embed')(embedding_layer)\n",
    "\n",
    "\n",
    "\n",
    "conv_1 = Conv1D(256,3,activation='relu',name='conv_1')(drop_embed_layer)\n",
    "maxp_1 = GlobalMaxPool1D(name='maxp_1')(conv_1)\n",
    "\n",
    "conv_2 = Conv1D(256,3,activation='relu',name='conv_2')(drop_embed_layer)\n",
    "maxp_2 = GlobalMaxPool1D(name='maxp_2')(conv_2)\n",
    "\n",
    "conv_3 = Conv1D(256,3,activation='relu',name='conv_3')(drop_embed_layer)\n",
    "maxp_3 = GlobalMaxPool1D(name='maxp_3')(conv_3)\n",
    "\n",
    "\n",
    "concat = concatenate([maxp_1,maxp_2,maxp_3])\n",
    "\n",
    "dense_layer = Dense(256,activation='relu',name='dense')(concat)\n",
    "drop_dense = Dropout(0.2, name='drop_dense')(dense_layer)\n",
    "\n",
    "predictions = Dense(1,activation='sigmoid',name='output')(drop_dense)\n",
    "\n",
    "model = Model(input_layer, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 128)     640000      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "drop_embed (SpatialDropout1D)   (None, 100, 128)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv1D)                 (None, 98, 256)      98560       drop_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv1D)                 (None, 98, 256)      98560       drop_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv1D)                 (None, 98, 256)      98560       drop_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maxp_1 (GlobalMaxPooling1D)     (None, 256)          0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxp_2 (GlobalMaxPooling1D)     (None, 256)          0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxp_3 (GlobalMaxPooling1D)     (None, 256)          0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 768)          0           maxp_1[0][0]                     \n",
      "                                                                 maxp_2[0][0]                     \n",
      "                                                                 maxp_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "drop_dense (Dropout)            (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            257         drop_dense[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,132,801\n",
      "Trainable params: 1,132,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
